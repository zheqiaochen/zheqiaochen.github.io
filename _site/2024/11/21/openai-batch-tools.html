<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Jekyll v3.9.5">
<meta property="og:title" content="A Toolkit for OpenAI Batch">
<meta name="author" content="Zheqiao Chen">
<meta property="og:locale" content="en">
<meta name="description" content="NEWS: I deployed the app online to make it easier to use. Visit openaibatch.vercel.app to give it a try!">
<meta property="og:description" content="NEWS: I deployed the app online to make it easier to use. Visit openaibatch.vercel.app to give it a try!">
<link rel="canonical" href="http://localhost:4000/2024/11/21/openai-batch-tools">
<meta property="og:url" content="http://localhost:4000/2024/11/21/openai-batch-tools">
<meta property="og:site_name" content="Zheqiao Chen’s Personal Website">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2024-11-21T00:00:00-05:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="A Toolkit for OpenAI Batch">
<meta name="twitter:site" content="@zheqiaoc">
<meta name="twitter:creator" content="@zheqiaoc"> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zheqiao Chen","url":"zheqiaoc.com"},"dateModified":"2024-11-21T00:00:00-05:00","datePublished":"2024-11-21T00:00:00-05:00","description":"NEWS: I deployed the app online to make it easier to use. Visit openaibatch.vercel.app to give it a try!","headline":"A Toolkit for OpenAI Batch","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/11/21/openai-batch-tools"},"url":"http://localhost:4000/2024/11/21/openai-batch-tools"}</script><title> A Toolkit for OpenAI Batch - Zheqiao Chen's Personal Website</title>
<link href="/favicon.png" rel="shortcut icon" media="(prefers-color-scheme: light)">
<link href="/favicon_dark.png" rel="shortcut icon" media="(prefers-color-scheme: dark)">
<link rel="alternate" type="application/atom+xml" title="Zheqiao Chen's Personal Website" href="/atom.xml">
<link rel="alternate" type="application/json" title="Zheqiao Chen's Personal Website" href="http://localhost:4000/feed.json">
<link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-KZJB8RH97S"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-KZJB8RH97S'); </script><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}:root{--primary-text: #1a1a1a;--secondary-text: #262626;--accent-color: #1a1a1a;--bg-color: #ffffff;--border-color: #d1d1d1;--hover-color: #333333;--code-bg: #fafafa;--blockquote-bg: #fafafa}@font-face{font-family:'Source Han Serif CN';src:local("Source Han Serif CN"),local("Source Han Serif SC"),local("Source Han Serif TC"),local("Source Han Serif TW"),local("Source Han Serif"),local("Noto Serif CJK SC"),local("Songti SC"),local("SimSong"),url("https://cdn.jsdelivr.net/gh/yihui/cron/fonts/SourceHanSerifCN-Regular-yihui.woff2") format("woff2");font-display:swap}@font-face{font-family:'Kai SC';src:local("Kaiti"),local("Kaiti SC"),local("STKaiti"),local("楷体"),local("SimKai"),local("AR PL KaitiM GB"),local("DFKai-SB"),local("FandolKai"),url("https://cdn.jsdelivr.net/gh/yihui/cron/fonts/gkai00mp-yihui.woff2") format("woff2");font-display:swap}body{font-family:Palatino, 'Palatino Linotype', 'Palatino LT STD', 'Latin Modern Roman', 'Source Han Serif CN', 'Noto Serif CJK SC', serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.8;font-size:1rem;color:var(--primary-text);background-color:var(--bg-color);max-width:100ch;margin:0 auto}nav ul{border-right:1px solid var(--border-color)}a{color:var(--accent-color);text-decoration:none;transition:all 0.2s ease}a:hover{color:var(--hover-color)}pre,code{font-family:Consolas, 'SF Mono', Monaco, 'Lucida Console', 'Courier New', 'Kai SC', monospace;font-size:0.95em;background:transparent}pre{margin:0;padding:0.5rem 0;overflow-x:auto;position:relative;padding-right:60px}pre code{padding:0;background:transparent;font-size:0.9em;line-height:1.6}.post{margin-bottom:3rem}.post-content{margin-bottom:4rem}.post p,.post h1,.post h2,.post h3,.post h4,.meta,li{margin:1rem 0}.post h1,.post h2,.post h3,.post h4,h1,h2,h3,h4,h5{line-height:1.3;font-weight:600}.post h4{margin-bottom:0.5rem;line-height:1.2}.post h2:first-child,.project h2:first-child,.photo h2:first-child,section h1:first-child{margin-top:0}header,section{padding:1rem}header li{margin-bottom:.2rem;text-align:right;margin-right:1rem}header a{text-decoration:none}header a.active{font-weight:bold}blockquote{font-family:'Palatino Linotype', 'Book Antiqua', Palatino, 'Kai SC', serif;margin:2rem 0;padding:1rem 1.5rem;border-left:4px solid var(--accent-color);background-color:var(--blockquote-bg);border-radius:0 6px 6px 0;font-style:normal;color:var(--secondary-text)}strong,b{font-weight:bold;font-size:0.9em}.photos ul,.posts ul,header ul{list-style:none}.posts li{display:flex;justify-content:space-between;align-items:center;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}.post ul,.project ul,.post ol{list-style-position:inside;margin-left:1rem;padding-left:1rem}img{max-width:100%}hr{background:#000000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}pre code{border:none}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem;padding-left:1.2rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid var(--border-color);padding-bottom:2rem}nav ul{border-right:0}.photos ul{margin-top:0.5rem}}section{flex-basis:0;flex-grow:999;min-width:77%;display:flex;flex-direction:column;margin-bottom:0;padding-bottom:0}figcaption{font-size:0.85rem}@media print{.no-print,.no-print *{display:none !important}}li{margin:4px 0;font-size:0.95rem}.highlight{border:1px solid var(--border-color);border-radius:8px;background-color:var(--code-bg);margin:1.5rem 0;position:relative;padding:1.2rem}.highlight:hover{box-shadow:0 2px 8px rgba(26,26,26,0.1);transition:box-shadow 0.2s ease}.highlight pre{margin:0;padding:0;background:transparent;border:none;overflow-x:auto}.highlight pre code{padding:0;background:transparent;border:none}.copy-code-button{position:absolute;top:0.8rem;right:0.8rem;background-color:var(--bg-color);color:var(--accent-color);padding:5px 10px;font-size:0.8rem;border:1px solid var(--border-color);border-radius:4px;cursor:pointer;z-index:10;transition:all 0.2s ease;font-family:-apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif}.copy-code-button:hover{background-color:var(--accent-color);color:var(--bg-color);border-color:var(--accent-color)}.copy-code-button:active{transform:scale(0.98)}.highlight .c,.highlight .cm,.highlight .c1{color:#595959;font-style:italic}.highlight .err,.highlight .ne{color:#a61717;background-color:#e3d2d2}.highlight .k,.highlight .o,.highlight .kc,.highlight .kd,.highlight .kp,.highlight .kr{font-weight:bold}.highlight .m,.highlight .mf,.highlight .mh,.highlight .mi,.highlight .mo{color:#d69e2e}.highlight .s,.highlight .sb,.highlight .sc,.highlight .sd,.highlight .s2,.highlight .se,.highlight .sh,.highlight .si,.highlight .sx,.highlight .sr,.highlight .s1,.highlight .ss{color:#262626}.highlight .nc,.highlight .kt{color:#445588;font-weight:bold}.highlight .gd{color:#000;background-color:#ffdddd}.highlight .gi{color:#000;background-color:#ddffdd}.highlight .na,.highlight .nv,.highlight .no,.highlight .ni,.highlight .vg,.highlight .vc,.highlight .vi{color:#1a1a1a}.post h1,h1{font-size:2.2rem;margin-bottom:2rem;color:var(--primary-text)}.post h2,h2{font-size:1.5rem;margin-top:1.8rem;padding-bottom:0.5rem;border-bottom:1px solid var(--border-color);color:var(--primary-text)}.post h3,h3{font-size:1.3rem}.post h4,h4{font-size:1.15rem}h5{font-size:1rem}#vcomments{margin-top:1.5rem;padding-top:1.5rem;border-top:1px solid var(--border-color);margin-bottom:0}.post p a,.post li a{color:var(--accent-color);text-decoration:underline;text-underline-offset:2px;text-decoration-thickness:1px}.post p a:hover,.post li a:hover{color:var(--hover-color)}em{font-family:'Palatino Linotype', 'Book Antiqua', Palatino, 'Kai SC', serif;font-style:normal}</style>
<script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} }); </script> <script type="text/javascript" async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="/assets/js/copyCode.js"></script>
</head>
<body><main><header aria-hidden="true" class="no-print"> <!--<h1 class="logo">Zheqiao Chen's Personal Website</h1>--><nav role="navigation" aria-hidden="true"><ul>
<li><a href="/">Writing</a></li>
<li><a href="/about">About</a></li>
<li><a href="/search">Search</a></li>
<li><a href="/rss.xml">RSS</a></li>
</ul></nav></header> ...<title>A Toolkit for OpenAI Batch</title>
<section class="post"><h2>A Toolkit for OpenAI Batch</h2>
<ul>
<li>
<a href="#what-is-openai-batch">What is OpenAI Batch?</a><ul>
<li><a href="#key-advantages-of-openai-batch">Key Advantages of OpenAI Batch</a></li>
<li><a href="#workflow-for-using-openai-batch">Workflow for Using OpenAI Batch</a></li>
</ul>
</li>
<li>
<a href="#what-can-openai-batch-tools-do">What Can OpenAI Batch Tools Do?</a><ul>
<li><a href="#menu-overview">Menu Overview</a></li>
<li><a href="#how-to-use">How to Use</a></li>
</ul>
</li>
</ul>
<p><strong>NEWS: I deployed the app online to make it easier to use. Visit <a href="https://openaibatch.vercel.app">openaibatch.vercel.app</a> to give it a try!</strong></p>
<p><strong>The online service may not be able to process large CSV files. If you encounter any error, please pull the app and run it on your local device.</strong></p>
<h2 id="what-is-openai-batch">What is OpenAI Batch?</h2>
<p>When using the OpenAI API for NLP tasks in social science research, I typically use the <code class="language-plaintext highlighter-rouge">openai</code> package with <code class="language-plaintext highlighter-rouge">pandas</code> to process CSV files, reading text and writing labels from OpenAI API responses. However, when a CSV file gets too large, the processing speed drops dramatically after handling a certain number of tasks. This is due to rate limits, as detailed in the <a href="https://platform.openai.com/docs/guides/rate-limits">rate limits documentation</a>.</p>
<p>To tackle large workloads more efficiently, the best approach is to use <a href="https://platform.openai.com/docs/guides/batch">OpenAI Batch</a>. With OpenAI Batch, users can upload a JSONL file in <a href="https://platform.openai.com/docs/guides/batch#1-preparing-your-batch-file">a specific format</a>. OpenAI processes the JSONL file (slower than standard API calls but more efficient for large jobs) and returns the results in the same format.</p>
<h3 id="key-advantages-of-openai-batch">Key Advantages of OpenAI Batch</h3>
<ul>
<li>
<strong>Higher daily usage limits</strong> compared to standard API calls.</li>
<li>Faster processing for large-scale NLP projects.</li>
</ul>
<h3 id="workflow-for-using-openai-batch">Workflow for Using OpenAI Batch</h3>
<p>Here’s a simple workflow I follow to classify a set of sentences using OpenAI Batch:</p>
<ol>
<li>Create a CSV file with my target sentences in one column.</li>
<li>Configure the task parameters and convert the CSV file to JSONL format.</li>
<li>Upload the JSONL file to the OpenAI Batch service. If there’s no error, wait for the results.</li>
<li>Download the processed JSONL file from the server and convert it back to a CSV file.</li>
</ol>
<h2 id="what-can-openai-batch-tools-do">What Can OpenAI Batch Tools Do?</h2>
<p>The above process requires some coding, and dealing with JSONL format and batch service limits can get pretty annoying. That’s why I made this app, which you can download <a href="https://github.com/zheqiaochen/openaibatch">here</a>.</p>
<h3 id="menu-overview">Menu Overview</h3>
<p>The app menu looks like this:</p>
<p><img src="https://i.ibb.co/Y2gFd1n/Screenshot-2024-11-21-at-11-46-32-PM.png" alt="menu"></p>
<p>It contains three tools to streamline the workflow:</p>
<ol>
<li><p><strong>CSV to JSONL Converter</strong><br> Converts a CSV file to JSONL format, which is required for OpenAI Batch processing.<br> <img src="https://i.ibb.co/cbbp2WW/Screenshot-2024-11-26-at-11-08-09-AM.png" alt="csv_to_jsonl"></p></li>
<li><p><strong>JSONL File Splitter</strong><br> Splits a JSONL file into smaller files of equal size. If the JSONL file exceeds batch service limits, you can split it into smaller files, register new OpenAI accounts to process them separately, and combine the results later.<br> <img src="https://i.ibb.co/KmkRr9v/Screenshot-2024-11-26-at-10-54-52-AM.png" alt="jsonl_splitter"></p></li>
<li><p><strong>JSONL Response Extractor</strong><br> After downloading batch outcomes from the OpenAI server, this feature extracts the responses and converts them back to a CSV file.<br> <img src="https://i.ibb.co/MscjT94/Screenshot-2024-11-26-at-10-54-55-AM.png" alt="jsonl_extractor"></p></li>
</ol>
<h3 id="how-to-use">How to Use</h3>
<p>First, prepare a CSV file as input. Specify the column that contains the text you want to analyze in the “Text Column” field, configure the other parameters, and click the “Convert” button to generate a JSONL file.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example of the parameters
</span>
<span class="c1"># Model: I often use gpt-4o-mini, which is cheap and strikes a good balance between speed and quality.
# Max Tokens: This is the maximum number of tokens shared between the prompt and the response. 
# One token is roughly 4 characters in English.
# Temperature: 1 is the default. A higher value gives more creative responses, a lower value gives more conservative ones.
</span></code></pre></div></div>
<p>Once the JSONL file is ready, you can upload it to the <a href="https://platform.openai.com/batches">OpenAI Batch service</a> to start processing.</p>
<p>After the batch service finishes processing, download the results and use the “JSONL Response Extractor” tool to convert them back to a CSV file.</p>
<p>Hope it can save you some time!</p>
<span class="meta"> <time datetime="2024-11-21T00:00:00-05:00">November 21, 2024</time> · <a href="/tag/app">app</a>, <a href="/tag/English">English</a> </span><div id="vcomments"></div></section><script src="/assets/js/copyCode.js"></script> <script src="/Valine.min.js"></script> <script> new Valine({ el:'#vcomments', appId: 'deLvV5QEsweui1qehWIOKa6h-gzGzoHsz', appKey: '5rlOhiv7dVJoeVuohXfQjzpP', avatar: "mp" }) </script></main></body>
</html>
